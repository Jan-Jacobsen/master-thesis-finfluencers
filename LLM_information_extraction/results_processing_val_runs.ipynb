{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Val Run Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Create scoring sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the finished val run result files (columns: ``video_id``, ``chunk_number``, ``output`` and ``error?``)\n",
    "\n",
    "- Read in data with labels and merge results from val runs\n",
    "\n",
    "- Arrange data in a convenient way for (for now: manual) scoring in excel sheet\n",
    "\n",
    "- save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_llama3_ft_v3_q8_0_llamacpp_guided.csv\n",
      "val_llama3_ft_v3_q8_0_llamacpp_unguided.csv\n",
      "val_llama3_ft_v4_q8_0_llamacpp_guided.csv\n",
      "val_llama3_ft_v4_q8_0_llamacpp_unguided.csv\n",
      "val_llama3_q8_0_llamacpp_guided.csv\n",
      "val_llama3_q8_0_llamacpp_unguided.csv\n",
      "val_mistral_q8_0_llamacpp_guided.csv\n",
      "val_mistral_q8_0_llamacpp_unguided.csv\n"
     ]
    }
   ],
   "source": [
    "# make sure that most recent progress files have been copied from google drive to repo!\n",
    "# load test run output data (all csv files in directory)\n",
    "\n",
    "test_run_path = \"../data/inference_results/val_runs\"\n",
    "\n",
    "# get all csv files in directory\n",
    "import os\n",
    "val_csv_names = [f for f in os.listdir(test_run_path) if f.endswith('.csv')]\n",
    "for f in val_csv_names:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 8)\n",
      "Index(['video_id', 'chunk_number', 'yt_video_type', 'uploader_id', 'title',\n",
      "       'first_three_tags', 'chunk_text', 'label', 'n_extracted', '0_output',\n",
      "       '0_error?', '0_n_extracted', '0_correct_empty', '0_correct_names',\n",
      "       '0_correct_asset_types', '0_correct_sentiments', '0_extra_neutrals',\n",
      "       '1_output', '1_error?', '1_n_extracted', '1_correct_empty',\n",
      "       '1_correct_names', '1_correct_asset_types', '1_correct_sentiments',\n",
      "       '1_extra_neutrals', '2_output', '2_error?', '2_n_extracted',\n",
      "       '2_correct_empty', '2_correct_names', '2_correct_asset_types',\n",
      "       '2_correct_sentiments', '2_extra_neutrals', '3_output', '3_error?',\n",
      "       '3_n_extracted', '3_correct_empty', '3_correct_names',\n",
      "       '3_correct_asset_types', '3_correct_sentiments', '3_extra_neutrals',\n",
      "       '4_output', '4_error?', '4_n_extracted', '4_correct_empty',\n",
      "       '4_correct_names', '4_correct_asset_types', '4_correct_sentiments',\n",
      "       '4_extra_neutrals', '5_output', '5_error?', '5_n_extracted',\n",
      "       '5_correct_empty', '5_correct_names', '5_correct_asset_types',\n",
      "       '5_correct_sentiments', '5_extra_neutrals', '6_output', '6_error?',\n",
      "       '6_n_extracted', '6_correct_empty', '6_correct_names',\n",
      "       '6_correct_asset_types', '6_correct_sentiments', '6_extra_neutrals',\n",
      "       '7_output', '7_error?', '7_n_extracted', '7_correct_empty',\n",
      "       '7_correct_names', '7_correct_asset_types', '7_correct_sentiments',\n",
      "       '7_extra_neutrals'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load labels and each csv file into a df\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# load labels (from labeling excel sheet)\n",
    "df = pd.read_excel(\"../data/transcript_chunks/labeling/labeling_sheet.xlsx\", sheet_name=\"VAL_labeling\", skiprows=1)\n",
    "df = df.drop(columns=[\"prompt\", \"done?\"])\n",
    "df = df.iloc[:, :df.columns.get_loc(\"label\")+1] # drop all columns after 'label' column\n",
    "print(df.shape)\n",
    "# add special column(s)\n",
    "df[\"n_extracted\"] = df[\"label\"].apply(lambda x: len(json.loads(x)))\n",
    "\n",
    "dtypes = {\n",
    "    'video_id': str,\n",
    "    'chunk_number': int,\n",
    "    'output': str,\n",
    "    'error?': bool}\n",
    "\n",
    "name_mapping = {}\n",
    "for i, f in enumerate(val_csv_names):\n",
    "    name_mapping[i] = f.replace(\".csv\", \"\").replace(\"val_\", \"\")\n",
    "\n",
    "    # load and prepare new df\n",
    "    new_df = pd.read_csv(f\"{test_run_path}/{f}\", sep=\";\", dtype=dtypes)\n",
    "    new_df = new_df.rename(columns={\"output\": f\"{i}_output\", \"error?\": f\"{i}_error?\"})\n",
    "\n",
    "    # merge new df\n",
    "    df = pd.merge(df, new_df, on=[\"video_id\", \"chunk_number\"], suffixes=(\"\", f\"_{i}\"))\n",
    "\n",
    "    # add scoring columns\n",
    "    # 1. columns which can be automatically computed\n",
    "    df[f\"{i}_n_extracted\"] = df[f\"{i}_output\"].apply(lambda x: len(json.loads(x)) if not pd.isnull(x) else 0)\n",
    "    df[f\"{i}_correct_empty\"] = (df[\"n_extracted\"] == 0) & (df[f\"{i}_n_extracted\"] == 0)\n",
    "    \n",
    "    # 2. columns which need manual input\n",
    "    # number of correct names extracted (can set to 0 already if n_extracted in the output or labels is 0)\n",
    "    # DO WE INCLUDE NEUTRALS in this?\n",
    "    df[f\"{i}_correct_names\"] = df.apply(lambda x: 0 if (x[\"n_extracted\"] == 0) | (x[f\"{i}_n_extracted\"] == 0) else None, axis=1)\n",
    "    # of correct names, how many asset types are correct?\n",
    "    df[f\"{i}_correct_asset_types\"] = df.apply(lambda x: 0 if x[f\"{i}_correct_names\"] == 0 else None, axis=1)\n",
    "    # of correct names, how many sentiments are correct?\n",
    "    df[f\"{i}_correct_sentiments\"] = df.apply(lambda x: 0 if x[f\"{i}_correct_names\"] == 0 else None, axis=1)\n",
    "    # additional neutrals extracted (-> should not be penalized?)\n",
    "    df[f\"{i}_extra_neutrals\"] = df.apply(lambda x: 0 if sum([1 for s in (json.loads(x[f\"{i}_output\"]) if not x[f\"{i}_error?\"] else []) if s[\"sentiment\"] == \"neutral\"]) == 0 else None, axis=1)\n",
    "\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv (for loading into excel)\n",
    "df.to_csv(\"../data/inference_results/val_runs_scoring/scoring_data_prepped.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'llama3_ft_v3_q8_0_llamacpp_guided',\n",
       " 1: 'llama3_ft_v3_q8_0_llamacpp_unguided',\n",
       " 2: 'llama3_ft_v4_q8_0_llamacpp_guided',\n",
       " 3: 'llama3_ft_v4_q8_0_llamacpp_unguided',\n",
       " 4: 'llama3_q8_0_llamacpp_guided',\n",
       " 5: 'llama3_q8_0_llamacpp_unguided',\n",
       " 6: 'mistral_q8_0_llamacpp_guided',\n",
       " 7: 'mistral_q8_0_llamacpp_unguided'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save name mapping to csv\n",
    "name_mapping_df = pd.DataFrame.from_dict(name_mapping, orient=\"index\", columns=[\"run_name\"])\n",
    "name_mapping_df[\"id\"] = name_mapping_df.index\n",
    "name_mapping_df.to_csv(\"../data/inference_results/val_runs_scoring/name_mapping.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Get Scores \n",
    "\n",
    "We want to examine model performance based on two types of statistics: \n",
    "\n",
    "##### I. Average of per-example scores\n",
    "This score should lie in a range from 0 to 1 for each example. We would like to consider two aspects of model performance: \n",
    "   - reward correct extractions (while considering not only the asset name but also asset type and sentiment)\n",
    "   - penalize mistakes (defined as extractions with wrong asset name and non-neutral sentiment).\n",
    "  \n",
    "We therefore build our metric out of two components:\n",
    "\n",
    "   - reward component: for each extracted asset, award +1 point if the name is correct. Another +1 each for correct type and sentiment. (If the asset name is wrong, no more points for type and sentiment can be awarded). Normalize by dividing by the maximum number of achievable points. Cases with $n_{\\text{labels}} = 0$ are handled separately to avoid division by zero (and to make perfect scores possible for these examples as well). The formula for the reward (between 0 and 1) is given by:\n",
    "  \n",
    "$$c_{\\text{reward}} = \n",
    "\\begin{cases} \n",
    "0 & \\text{for } n_{\\text{labels}} = 0 \\\\\n",
    "\\frac{n_{\\text{correct names}} + n_{\\text{correct types}} + n_{\\text{correct sentiments}}}{3 \\cdot n_{\\text{labels}}} & \\text{else. (}\\Rightarrow n_{\\text{labels}} > 0 \\text{)}\\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "   - penalty component: since there is no maximum possible number of mistakes, we take the number of labeled assets for the example as the limit at which the maximum penalty is applied. The formula for the penalty (between 0 and 1) therefore is given by: \n",
    "\n",
    "$$\\text{penalty} = \n",
    "\\begin{cases} \n",
    "0 & \\text{for } n_{\\text{labels}} = n_{\\text{mistakes}} = 0 \\\\\n",
    "1 & \\text{for } n_{\\text{mistakes}} > n_{\\text{labels}} \\\\\n",
    "\\frac{n_{\\text{mistakes}}}{n_{\\text{labels}}} & \\text{else. (} n_{\\text{mistakes}} \\leq n_{\\text{labels}} \\text{ and } n_{\\text{labels}} > 0 \\text{)}\\\\\n",
    "\n",
    "\\end{cases}$$\n",
    "\n",
    "   To combine the two components into a single score between 0 and 1, we transform the penalty to a reward by subtracting it from 1 and then take the average of the two components. (Here we could also weight reward and penalty differently according to our preferences.) We also have to consider the case of $n_{labels} = 0$ (and errors from unguided generation) separately to avoid division by zero. \n",
    "\n",
    "$$\\text{score} = a \\cdot \\text{reward} + (1 - a) \\cdot (1 - \\text{penalty})$$\n",
    "\n",
    "This approach will put less weight on the few outliers with a very high number of mentioned assets (e.g. 20+) which highly influence the overall totals. \n",
    "Meanwhile, examples with no extractions to be made ($n_labels = 0$) have a big influence, since a 100% score is possible for them and they appear frequently in our data. To get as clear a picture as possible, we will compute the final scores for the validation run WITH and WITHOUT empty examples.\n",
    "\n",
    "##### II. Totals over validation dataset\n",
    "\n",
    "   - Error rate (for unguided generation)\n",
    "   - correct asset names\n",
    "   - correct asset types (if name is correct)\n",
    "   - correct sentiments (if name is correct)\n",
    "   - mistakes in asset names\n",
    "\n",
    "\n",
    "Looking at the totals as a scoring approach will put more importance on the outliers with a high number of assets mentioned in the example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scoring function\n",
    "def get_score(row, id, reward_weight=0.5):\n",
    "    n_labels = row[\"n_extracted\"] # ground truth\n",
    "    n_extracted = row[f\"{id}_n_extracted\"] # model output\n",
    "    n_correct_names = row[f\"{id}_correct_names\"]\n",
    "    n_correct_asset_types = row[f\"{id}_correct_asset_types\"]\n",
    "    n_correct_sentiments = row[f\"{id}_correct_sentiments\"]\n",
    "    n_extra_neutrals = row[f\"{id}_extra_neutrals\"]\n",
    "    n_mistakes = row[f\"{id}_n_mistakes\"] # not in scoring sheet, compute before calling this function!\n",
    "    \n",
    "    # compute reward component\n",
    "    if n_labels == 0 and n_mistakes > 0:\n",
    "        reward = 0\n",
    "    elif n_labels == 0 and n_mistakes == 0: # empty labels and correct (no) extractions ->, what should the reward be here? I think 0 is better to avoid rewarding very conservative models too much on our dataset\n",
    "        reward = 0\n",
    "    else:\n",
    "        reward = (n_correct_names + n_correct_asset_types + n_correct_sentiments) / (n_labels * 3)\n",
    "    \n",
    "    # compute penalty component\n",
    "    if n_labels == 0 and n_mistakes == 0:\n",
    "        penalty = 0\n",
    "    elif n_mistakes > 0:\n",
    "        penalty = 1\n",
    "    else:\n",
    "        penalty = n_mistakes / n_labels\n",
    "    \n",
    "    # compute final score\n",
    "    score = reward_weight * reward + (1 - reward_weight) * (1 - penalty)\n",
    "    return score\n",
    "\n",
    "# helper function to compute n_mistakes column\n",
    "def get_n_mistakes(row, id):\n",
    "    # mistake is defined as wrong asset name and non-neutral sentiment\n",
    "    n_mistakes = row[f\"{id}_n_extracted\"] - row[f\"{id}_correct_names\"] - row[f\"{id}_extra_neutrals\"]\n",
    "\n",
    "    if n_mistakes < 0: # should not happen but manual scoring sheet could theoretically contain errors\n",
    "        print(f\"Warning: n_mistakes < 0 for video_id {row['video_id']}, chunk_number {row['chunk_number']}, run {id}! (n_mistakes set from {n_mistakes} to 0.)\")\n",
    "        n_mistakes = 0\n",
    "    return n_mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in scoring sheet and name mapping\n",
    "import pandas as pd\n",
    "df = pd.read_excel(\"../data/inference_results/val_runs_scoring/scoring_sheet.xlsx\", sheet_name=\"scoring_data_prepped\")\n",
    "name_mapping = pd.read_csv(\"../data/inference_results/val_runs_scoring/name_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each run, compute per-example scores\n",
    "for id, run_name in zip(name_mapping[\"id\"], name_mapping[\"run_name\"]):\n",
    "    df[f\"{id}_n_mistakes\"] = df.apply(get_n_mistakes, axis=1, id=id)\n",
    "    df[f\"{id}_score_0.33\"] = df.apply(get_score, axis=1, id=id, reward_weight=0.33)\n",
    "    df[f\"{id}_score_0.5\"] = df.apply(get_score, axis=1, id=id, reward_weight=0.5)\n",
    "    df[f\"{id}_score_0.67\"] = df.apply(get_score, axis=1, id=id, reward_weight=0.67)\n",
    "\n",
    "# get aggregated data for each run (two versions: with and without zero labels (i.e. '[]' examples))\n",
    "agg_data = {}\n",
    "agg_data_without_zero_labels = {}\n",
    "\n",
    "for dict, data in zip([agg_data, agg_data_without_zero_labels], [df.copy(), df[df[\"n_extracted\"] > 0].copy()]):\n",
    "    for id, run_name in zip(name_mapping[\"id\"], name_mapping[\"run_name\"]):\n",
    "\n",
    "        dict[run_name] = {\n",
    "            # for convenience/later use\n",
    "            \"run_id\": id,\n",
    "            \"run_name\": run_name,\n",
    "            \"guided_model\": True if \"_guided\" in run_name else False,\n",
    "            \"n_examples\": data.shape[0],\n",
    "            # means\n",
    "            \"mean_score_0.33\": data[f\"{id}_score_0.33\"].mean(),\n",
    "            \"mean_score_0.5\": data[f\"{id}_score_0.5\"].mean(),\n",
    "            \"mean_score_0.67\": data[f\"{id}_score_0.67\"].mean(),\n",
    "            \"invalid_output_rate\": data[f\"{id}_error?\"].mean(),\n",
    "            # totals\n",
    "            \"n_labels\": data[\"n_extracted\"].sum(), # ground truth\n",
    "            \"n_correct_names\": data[f\"{id}_correct_names\"].sum(),\n",
    "            \"n_correct_asset_types\": data[f\"{id}_correct_asset_types\"].sum(),\n",
    "            \"n_correct_sentiments\": data[f\"{id}_correct_sentiments\"].sum(),\n",
    "            \"n_mistakes\": data[f\"{id}_n_mistakes\"].sum(),\n",
    "            \"n_extra_neutrals\": data[f\"{id}_extra_neutrals\"].sum(),\n",
    "        }\n",
    "\n",
    "# convert dicts to dfs\n",
    "agg_data_df = pd.DataFrame.from_dict(agg_data, orient=\"index\").reset_index(drop=True)\n",
    "agg_data_without_zero_labels_df = pd.DataFrame.from_dict(agg_data_without_zero_labels, orient=\"index\").reset_index(drop=True)\n",
    "\n",
    "# save to csv\n",
    "agg_data_df.to_csv(\"../data/inference_results/val_runs_scoring/scoring_results.csv\", sep=\";\", index=False)\n",
    "agg_data_without_zero_labels_df.to_csv(\"../data/inference_results/val_runs_scoring/scoring_results_without_zero_labels.csv\", sep=\";\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>guided_model</th>\n",
       "      <th>n_examples</th>\n",
       "      <th>mean_score_0.33</th>\n",
       "      <th>mean_score_0.5</th>\n",
       "      <th>mean_score_0.67</th>\n",
       "      <th>invalid_output_rate</th>\n",
       "      <th>n_labels</th>\n",
       "      <th>n_correct_names</th>\n",
       "      <th>n_correct_asset_types</th>\n",
       "      <th>n_correct_sentiments</th>\n",
       "      <th>n_mistakes</th>\n",
       "      <th>n_extra_neutrals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>llama3_ft_v3_q8_0_llamacpp_guided</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "      <td>0.700544</td>\n",
       "      <td>0.556582</td>\n",
       "      <td>0.412620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>llama3_ft_v3_q8_0_llamacpp_unguided</td>\n",
       "      <td>False</td>\n",
       "      <td>150</td>\n",
       "      <td>0.702011</td>\n",
       "      <td>0.558804</td>\n",
       "      <td>0.415598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>llama3_ft_v4_q8_0_llamacpp_guided</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "      <td>0.681362</td>\n",
       "      <td>0.565297</td>\n",
       "      <td>0.449231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>llama3_ft_v4_q8_0_llamacpp_unguided</td>\n",
       "      <td>False</td>\n",
       "      <td>150</td>\n",
       "      <td>0.676896</td>\n",
       "      <td>0.561963</td>\n",
       "      <td>0.447031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>llama3_q8_0_llamacpp_guided</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "      <td>0.542754</td>\n",
       "      <td>0.475486</td>\n",
       "      <td>0.408218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>100</td>\n",
       "      <td>75</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>llama3_q8_0_llamacpp_unguided</td>\n",
       "      <td>False</td>\n",
       "      <td>150</td>\n",
       "      <td>0.551834</td>\n",
       "      <td>0.465203</td>\n",
       "      <td>0.378572</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>158</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>71</td>\n",
       "      <td>47</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>mistral_q8_0_llamacpp_guided</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "      <td>0.674301</td>\n",
       "      <td>0.537426</td>\n",
       "      <td>0.400551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>mistral_q8_0_llamacpp_unguided</td>\n",
       "      <td>False</td>\n",
       "      <td>150</td>\n",
       "      <td>0.666227</td>\n",
       "      <td>0.514889</td>\n",
       "      <td>0.363551</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>158</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id                             run_name  guided_model  n_examples  \\\n",
       "0       0    llama3_ft_v3_q8_0_llamacpp_guided          True         150   \n",
       "1       1  llama3_ft_v3_q8_0_llamacpp_unguided         False         150   \n",
       "2       2    llama3_ft_v4_q8_0_llamacpp_guided          True         150   \n",
       "3       3  llama3_ft_v4_q8_0_llamacpp_unguided         False         150   \n",
       "4       4          llama3_q8_0_llamacpp_guided          True         150   \n",
       "5       5        llama3_q8_0_llamacpp_unguided         False         150   \n",
       "6       6         mistral_q8_0_llamacpp_guided          True         150   \n",
       "7       7       mistral_q8_0_llamacpp_unguided         False         150   \n",
       "\n",
       "   mean_score_0.33  mean_score_0.5  mean_score_0.67  invalid_output_rate  \\\n",
       "0         0.700544        0.556582         0.412620             0.000000   \n",
       "1         0.702011        0.558804         0.415598             0.000000   \n",
       "2         0.681362        0.565297         0.449231             0.000000   \n",
       "3         0.676896        0.561963         0.447031             0.000000   \n",
       "4         0.542754        0.475486         0.408218             0.000000   \n",
       "5         0.551834        0.465203         0.378572             0.133333   \n",
       "6         0.674301        0.537426         0.400551             0.000000   \n",
       "7         0.666227        0.514889         0.363551             0.086667   \n",
       "\n",
       "   n_labels  n_correct_names  n_correct_asset_types  n_correct_sentiments  \\\n",
       "0       158               61                     61                    60   \n",
       "1       158               63                     63                    62   \n",
       "2       158               97                     95                    85   \n",
       "3       158               97                     95                    85   \n",
       "4       158              117                    115                   100   \n",
       "5       158               85                     84                    71   \n",
       "6       158               78                     77                    57   \n",
       "7       158               28                     28                    22   \n",
       "\n",
       "   n_mistakes  n_extra_neutrals  \n",
       "0           3                 1  \n",
       "1           4                 0  \n",
       "2          17                 6  \n",
       "3          18                 5  \n",
       "4          75                83  \n",
       "5          47                69  \n",
       "6          13                30  \n",
       "7           7                 7  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>guided_model</th>\n",
       "      <th>n_examples</th>\n",
       "      <th>mean_score_0.33</th>\n",
       "      <th>mean_score_0.5</th>\n",
       "      <th>mean_score_0.67</th>\n",
       "      <th>invalid_output_rate</th>\n",
       "      <th>n_labels</th>\n",
       "      <th>n_correct_names</th>\n",
       "      <th>n_correct_asset_types</th>\n",
       "      <th>n_correct_sentiments</th>\n",
       "      <th>n_mistakes</th>\n",
       "      <th>n_extra_neutrals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>llama3_ft_v3_q8_0_llamacpp_guided</td>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>0.767252</td>\n",
       "      <td>0.666432</td>\n",
       "      <td>0.565611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>llama3_ft_v3_q8_0_llamacpp_unguided</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "      <td>0.758919</td>\n",
       "      <td>0.663345</td>\n",
       "      <td>0.567771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>llama3_ft_v4_q8_0_llamacpp_guided</td>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>0.788414</td>\n",
       "      <td>0.746194</td>\n",
       "      <td>0.703974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>llama3_ft_v4_q8_0_llamacpp_unguided</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "      <td>0.788414</td>\n",
       "      <td>0.746194</td>\n",
       "      <td>0.703974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>llama3_q8_0_llamacpp_guided</td>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>0.688762</td>\n",
       "      <td>0.709684</td>\n",
       "      <td>0.730607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>100</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>llama3_q8_0_llamacpp_unguided</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "      <td>0.676762</td>\n",
       "      <td>0.653343</td>\n",
       "      <td>0.629924</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>158</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>71</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>mistral_q8_0_llamacpp_guided</td>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>0.706762</td>\n",
       "      <td>0.622479</td>\n",
       "      <td>0.538197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>mistral_q8_0_llamacpp_unguided</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "      <td>0.684333</td>\n",
       "      <td>0.559877</td>\n",
       "      <td>0.435420</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>158</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id                             run_name  guided_model  n_examples  \\\n",
       "0       0    llama3_ft_v3_q8_0_llamacpp_guided          True          54   \n",
       "1       1  llama3_ft_v3_q8_0_llamacpp_unguided         False          54   \n",
       "2       2    llama3_ft_v4_q8_0_llamacpp_guided          True          54   \n",
       "3       3  llama3_ft_v4_q8_0_llamacpp_unguided         False          54   \n",
       "4       4          llama3_q8_0_llamacpp_guided          True          54   \n",
       "5       5        llama3_q8_0_llamacpp_unguided         False          54   \n",
       "6       6         mistral_q8_0_llamacpp_guided          True          54   \n",
       "7       7       mistral_q8_0_llamacpp_unguided         False          54   \n",
       "\n",
       "   mean_score_0.33  mean_score_0.5  mean_score_0.67  invalid_output_rate  \\\n",
       "0         0.767252        0.666432         0.565611             0.000000   \n",
       "1         0.758919        0.663345         0.567771             0.000000   \n",
       "2         0.788414        0.746194         0.703974             0.000000   \n",
       "3         0.788414        0.746194         0.703974             0.000000   \n",
       "4         0.688762        0.709684         0.730607             0.000000   \n",
       "5         0.676762        0.653343         0.629924             0.203704   \n",
       "6         0.706762        0.622479         0.538197             0.000000   \n",
       "7         0.684333        0.559877         0.435420             0.222222   \n",
       "\n",
       "   n_labels  n_correct_names  n_correct_asset_types  n_correct_sentiments  \\\n",
       "0       158               61                     61                    60   \n",
       "1       158               63                     63                    62   \n",
       "2       158               97                     95                    85   \n",
       "3       158               97                     95                    85   \n",
       "4       158              117                    115                   100   \n",
       "5       158               85                     84                    71   \n",
       "6       158               78                     77                    57   \n",
       "7       158               28                     28                    22   \n",
       "\n",
       "   n_mistakes  n_extra_neutrals  \n",
       "0           2                 0  \n",
       "1           4                 0  \n",
       "2           7                 1  \n",
       "3           7                 1  \n",
       "4          23                20  \n",
       "5          16                11  \n",
       "6          11                18  \n",
       "7           5                 7  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data_without_zero_labels_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
