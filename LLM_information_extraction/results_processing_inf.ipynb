{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Check Output Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the full dataset (inference, finetuning and validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "import jsonschema\n",
    "data_path = \"../data\"\n",
    "\n",
    "# read in model outputs and join with finetuning and valid labels to get complete dataset\n",
    "\n",
    "# model outputs\n",
    "inf_file_name = \"inf_llama3_ft_v4_q8_0_llamacpp_guided\"\n",
    "inf_path = f\"{data_path}/inference_results/inf_runs/{inf_file_name}.csv\"\n",
    "# finetuning labels\n",
    "ft_file_name = \"FT_transcript_chunks_nvids45968_chunksize2048_overlap50_tokMistral_with_metadata_for_prompt_with_labels\"\n",
    "ft_path = f\"{data_path}/transcript_chunks/splits/{ft_file_name}.csv\"\n",
    "# valid labels\n",
    "val_file_name = \"VAL_transcript_chunks_nvids45968_chunksize2048_overlap50_tokMistral_with_metadata_for_prompt_with_labels\"\n",
    "val_path = f\"{data_path}/transcript_chunks/splits/{val_file_name}.csv\"\n",
    "\n",
    "# read in data\n",
    "inf_df = pd.read_csv(inf_path, sep=\";\")\n",
    "ft_df = pd.read_csv(ft_path, sep=\";\")\n",
    "val_df = pd.read_csv(val_path, sep=\";\")\n",
    "\n",
    "### adjust columns\n",
    "\n",
    "# add split and error? cols\n",
    "inf_df[\"split\"] = \"inf\"\n",
    "\n",
    "ft_df[\"error?\"] = False \n",
    "ft_df[\"split\"] = \"ft\"\n",
    "\n",
    "val_df[\"error?\"] = False\n",
    "val_df[\"split\"] = \"val\"\n",
    "\n",
    "# rename\n",
    "inf_df = inf_df.rename(columns={\"output\": \"label\"})\n",
    "# keep only relevant columns\n",
    "cols = [\"video_id\", \"chunk_number\", \"label\", \"error?\", \"split\"]\n",
    "ft_df = ft_df[cols]\n",
    "val_df = val_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80176, 5)\n"
     ]
    }
   ],
   "source": [
    "# join\n",
    "df = pd.concat([inf_df, ft_df, val_df])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing labels and/or errors\n"
     ]
    }
   ],
   "source": [
    "# show missing labels and/or error rows\n",
    "problem_rows = df[(df[\"label\"].isna()) | (df[\"error?\"])]\n",
    "if problem_rows.shape[0] > 0:\n",
    "    print(problem_rows)\n",
    "else:\n",
    "    print(\"No missing labels and/or errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLM_utils import output_json_schema_string\n",
    "\n",
    "if False: # runs ~ 2 min\n",
    "    # check for any invalid json in outputs\n",
    "    def matches_schema(string, schema):\n",
    "        try:\n",
    "            jsonschema.validate(json.loads(string), schema)\n",
    "            return True\n",
    "        except jsonschema.ValidationError:\n",
    "            return False\n",
    "    # check model outputs against schema defined in LLM_utils\n",
    "    schema_match = df[\"label\"].apply(lambda x: matches_schema(x, json.loads(output_json_schema_string)))\n",
    "    if schema_match.sum() < df.shape[0]:\n",
    "        print(\"Some outputs do not match schema\")\n",
    "        print(schema_match.value_counts())\n",
    "    else:\n",
    "        print(\"No invalid json found in outputs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of extractions: 74551\n"
     ]
    }
   ],
   "source": [
    "# total number of extracted assets\n",
    "n_assets = df[\"label\"].apply(lambda x: len(json.loads(x))).sum()\n",
    "print(f\"Total number of extractions: {n_assets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Asset Name Matching\n",
    "\n",
    "Using the matching processes defined in ``name_matching_utils.py`` we try to match the appropriate ticker to every asset_name in the outputs. We add the entire ``match_info`` dict returned by the matching function to every label as a fourth object. (might be useful to compute matching statistics later). \n",
    "\n",
    "Note that with pre-processing the candidate dicts, the matching functions are fast enough to allow us to simply iterate over every extracted label and get the matching results. Matching is deterministic as well. If it wasn't, or if efficiency was a bigger concern, we could first find the set of unique extracted names and match only those, avoiding repeated work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from name_matching_utils import load_candidate_dicts, match_stock, match_etf, match_crypto, match_commodity\n",
    "\n",
    "candidate_dicts = load_candidate_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_matches_to_label(label_str):\n",
    "    label_json = json.loads(label_str)\n",
    "    for asset in label_json:\n",
    "        if asset[\"asset_type\"] == \"stock\":\n",
    "            asset[\"match_info\"] = match_stock(asset[\"asset_name\"], **candidate_dicts[\"stocks\"])\n",
    "        elif asset[\"asset_type\"] == \"etf\":\n",
    "            asset[\"match_info\"] = match_etf(asset[\"asset_name\"], **candidate_dicts[\"etfs\"])\n",
    "        elif asset[\"asset_type\"] == \"crypto\":\n",
    "            asset[\"match_info\"] = match_crypto(asset[\"asset_name\"], **candidate_dicts[\"cryptos\"])\n",
    "        elif asset[\"asset_type\"] == \"commodity\":\n",
    "            asset[\"match_info\"] = match_commodity(asset[\"asset_name\"], **candidate_dicts[\"commodities\"])\n",
    "        elif asset[\"asset_type\"] == \"other\":\n",
    "            # catch-all for asset types outside our scope -> no matching (could also enter empty match_info dict)\n",
    "            pass\n",
    "    return json.dumps(label_json)\n",
    "\n",
    "# add matches to all labels\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: add_matches_to_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save matched version of chunk labels df\n",
    "df.to_csv(f\"{data_path}/matched/CHUNKS_{inf_file_name}.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recombining Chunks (dealing with duplicate assets)\n",
    "\n",
    "Now that we have a matched chunk-level dataset, we can recombine the chunk-level into video-level data. For cases where the same asset appears in multiple chunks of a video (or even multiple times in the same chunk), we abide by the following rules:\n",
    "\n",
    "1. Disagreements in sentiment:\n",
    "     - for three-way disagreements: keep first neutral one\n",
    "     - for buy/sell disagreements: create neutral one from first\n",
    "     - for buy/neutral or sell/neutral disagreements: keep first non-neutral one\n",
    "\n",
    "2. (Remaining) disagreements in asset_type:\n",
    "     - can only happen with stocks/commodities or etfs/commodities\n",
    "     -> keep only the one with type ``commodity``\n",
    "\n",
    "3. (Remaining) disagreements in asset_name:\n",
    "     - just keep the first one\n",
    "\n",
    "Importantly, we must take measures to apply the rules above separately to cryptos and non-crypto assets, because cryptos can share tickers with stocks/etfs/commodities (but obviously refer to different underlying assets). We implement this by adding a prefix to crypto tickers before processing (and removing it afterwards). \n",
    "\n",
    "To preserve all information we keep two columns: one with a list of all extractions, and one freed of duplicates via the rules above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load matched data\n",
    "chunks_df = pd.read_csv(f\"{data_path}/matched/CHUNKS_{inf_file_name}.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunks_to_video_utils import deduplicate_asset_list\n",
    "\n",
    "# obtain video-level dataframe\n",
    "video_df = chunks_df.sort_values(by=[\"video_id\", \"chunk_number\"]).groupby([\"video_id\"]).agg({\"label\": lambda x: json.dumps([asset for chunk_list in x for asset in json.loads(chunk_list)])})\n",
    "video_df = video_df.reset_index().rename(columns={\"label\": \"extractions_all\"})\n",
    "\n",
    "# deduplicated column, retaining unmatched\n",
    "video_df[\"extractions_dedup_retain_unmatched\"] = video_df[\"extractions_all\"].apply(lambda x: json.dumps(deduplicate_asset_list(json.loads(x), retain_unmatched=True)))\n",
    "# deduplicated column, removing unmatched assets\n",
    "video_df[\"extractions_dedup\"] = video_df[\"extractions_all\"].apply(lambda x: json.dumps(deduplicate_asset_list(json.loads(x), retain_unmatched=False)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add two more columns with stripped-down versions (without match_info etc.) of the extractions, i.e. list of asset dicts with three keys only: ``asset_type``, ``ticker``, ``sentiment``.\n",
    "- ``trade_info_incl_neutrals``\n",
    "- ``trade_info_no_neutrals`` (not including extractions with neutral sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def filter_for_trade_info(asset):\n",
    "    return {\"asset_type\": asset[\"asset_type\"], \n",
    "             \"ticker\": asset[\"match_info\"][\"matched_ticker\"],\n",
    "             \"sentiment\": asset[\"sentiment\"]}\n",
    "\n",
    "video_df[\"trade_info_incl_neutrals\"] = video_df[\"extractions_dedup\"].apply(lambda x: json.dumps([filter_for_trade_info(a) for a in json.loads(x)]))\n",
    "video_df[\"trade_info_no_neutrals\"] = video_df[\"extractions_dedup\"].apply(lambda x: json.dumps([filter_for_trade_info(a) for a in json.loads(x) if a[\"sentiment\"] != \"neutral\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save video-level df\n",
    "video_df.to_csv(f\"{data_path}/matched/VIDEOS_{inf_file_name}.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later we will join this dataset with the video upload dates (necessary for building portfolios) and other metadata which could be interesting for further analysis. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
